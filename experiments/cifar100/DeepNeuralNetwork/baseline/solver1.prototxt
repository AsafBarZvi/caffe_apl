# reduce the learning rate after 8 epochs (4000 iters) by a factor of 10

# The training protocol buffer definition
train_net: "3Conv/baseline/train1.prototxt"
# The testing protocol buffer definition
test_net: "3Conv/baseline/test1.prototxt"
# test_iter specifies how many forward passes the test should carry out.
# In the case of MNIST, we have test batch size 100 and 100 test iterations,
# covering the full 10,000 testing images.
test_iter: 100
# Carry out testing every 500 training iterations.
test_interval: 1000
# The base learning rate, momentum and the weight decay of the network.
base_lr: 0.001
momentum: 0.5
max_momentum: 0.9
momentum_change_steps: 10000
weight_decay: 0.001

device_id: 2

# The learning rate policy

#lr_policy: "exp"
#gamma: 0.99997

#lr_policy: "inverse_t"
#gamma: 10000

lr_policy: "preset"
lr: 0.001
lr_change: 80000
lr: 0.0005
lr_change: 100000
lr: 0.0001
lr_change: 120000
lr: 0.00001
lr_change: 150000

#lr_policy: "fixed"

#lr_policy: "step"
#gamma: 0.1
#stepsize: 60000

#lr_policy: "manual_step"
#iter_change: 30
#rate_mult: 0.1
#min_rate: 0.00001 



# Display every 100 iterations
display: 200
# The maximum number of iterations
max_iter: 900000
# snapshot intermediate results
snapshot: 20000
snapshot_prefix: "3Conv/baseline/solverstate/dummy1"
# solver mode: CPU or GPU
solver_mode: GPU
